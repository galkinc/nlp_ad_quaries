{"nbformat":4,"nbformat_minor":4,"metadata":{"colab":{"name":"SmallCategorising 3","provenance":[],"collapsed_sections":[],"history_visible":true},"kernelspec":{"name":"python3","display_name":"Yandex DataSphere Kernel","language":"python"},"language_info":{"codemirror_mode":{"version":3,"name":"ipython"},"mimetype":"text/x-python","version":"3.7.7","file_extension":".py","pygments_lexer":"ipython3","nbconvert_exporter":"python","name":"python"},"notebookId":"feffce2b-5df0-4fc2-805d-13371a703736"},"cells":[{"cell_type":"markdown","source":"# 1 Preparing","metadata":{"id":"pWoBMyZkLXfr","cellId":"u9sjy7wmfkgsraea8jj80j"}},{"cell_type":"code","source":"%pip install pymystem3","metadata":{"cellId":"vrc3tb5hmijwolcrviecp","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"Defaulting to user installation because normal site-packages is not writeable\nRequirement already satisfied: pymystem3 in /home/jupyter/.local/lib/python3.7/site-packages (0.2.0)\nRequirement already satisfied: requests in /kernel/lib/python3.7/site-packages (from pymystem3) (2.25.1)\nRequirement already satisfied: certifi>=2017.4.17 in /kernel/lib/python3.7/site-packages (from requests->pymystem3) (2021.5.30)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /kernel/lib/python3.7/site-packages (from requests->pymystem3) (1.26.6)\nRequirement already satisfied: chardet<5,>=3.0.2 in /kernel/lib/python3.7/site-packages (from requests->pymystem3) (4.0.0)\nRequirement already satisfied: idna<3,>=2.5 in /kernel/lib/python3.7/site-packages (from requests->pymystem3) (2.10)\n\u001B[33mWARNING: You are using pip version 21.0.1; however, version 21.2.4 is available.\nYou should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\u001B[0m\n"}],"execution_count":966},{"cell_type":"code","source":"%pip install xlrd","metadata":{"cellId":"mg8xsecv1si475hlxcpl","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"Defaulting to user installation because normal site-packages is not writeable\nRequirement already satisfied: xlrd in /home/jupyter/.local/lib/python3.7/site-packages (2.0.1)\n\u001B[33mWARNING: You are using pip version 21.0.1; however, version 21.2.4 is available.\nYou should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\u001B[0m\n"}],"execution_count":967},{"cell_type":"code","source":"%pip install openpyxl","metadata":{"cellId":"657c8yhwqt4oter80ai2mk","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"Defaulting to user installation because normal site-packages is not writeable\nRequirement already satisfied: openpyxl in /home/jupyter/.local/lib/python3.7/site-packages (3.0.8)\nRequirement already satisfied: et-xmlfile in /home/jupyter/.local/lib/python3.7/site-packages (from openpyxl) (1.1.0)\n\u001B[33mWARNING: You are using pip version 21.0.1; however, version 21.2.4 is available.\nYou should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\u001B[0m\n"}],"execution_count":968},{"cell_type":"code","source":"%pip install pymorphy2","metadata":{"cellId":"d2gidpusedsrxokty976an","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"Defaulting to user installation because normal site-packages is not writeable\nRequirement already satisfied: pymorphy2 in /usr/local/lib/python3.7/dist-packages (0.9.1)\nRequirement already satisfied: dawg-python>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from pymorphy2) (0.7.2)\nRequirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from pymorphy2) (2.4.417127.4579844)\nRequirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2) (0.6.2)\n\u001B[33mWARNING: You are using pip version 21.0.1; however, version 21.2.4 is available.\nYou should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\u001B[0m\n"}],"execution_count":969},{"cell_type":"code","source":"import pandas as pd\nimport regex as rg\nimport numpy as np\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import metrics\nfrom sklearn.model_selection import GridSearchCV\n\nimport string\nfrom pymystem3 import Mystem\n\nimport pickle\n\nimport pymorphy2\n\nimport os\nfrom pathlib import Path","metadata":{"id":"f_UW-hZWUzsE","cellId":"lcjl419yzuit5o690eypib","trusted":true},"outputs":[],"execution_count":970},{"cell_type":"code","source":"# import nltk\n# nltk.download('stopwords')\n# nltk.download('punkt')\n# from nltk.corpus import stopwords\n\n# STOPWORDS = set(stopwords.words(\"russian\"))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1R38ZRAzhMM9","outputId":"7194b119-5b09-4d6a-d379-1085de7e0626","cellId":"2wxa13h91fx7rlfh6oiiv8","trusted":true},"outputs":[],"execution_count":971},{"cell_type":"markdown","source":"# 2 Load data and prepare  setrs","metadata":{"id":"prnYJsh1Lgci","cellId":"t4wnegz1xt0wnkqbv7z7mk"}},{"cell_type":"code","source":"class_file = {}\ndictionary_files = {}\n\n# *** root directory ***\npwd = '/home/jupyter/work/resources'\n\n# Target dataset (which is used for the true classification)\nkey_value = \"coffee.xlsx\"\ndict_name = 'coffee_dict.xlsx'\n\n# *** Datasets ***\ndataset_path = pwd + '/content/datasets/'\nfor entry in os.listdir(dataset_path):\n    if os.path.isfile(os.path.join(dataset_path, entry)):\n        class_file[entry] = dataset_path + entry\n\n# *** Dictionaries with brands and support words ***\n# PLS be shure that name of the support dectionary file is equal with \"dict_name\"\ndataset_path = pwd + '/content/dictionaries/'\nfor entry in os.listdir(dataset_path):\n    if os.path.isfile(os.path.join(dataset_path, entry)):\n        dictionary_files[entry] = dataset_path + entry\n\n# used for datasets fields\n# req_str - text of requests\n# cls_str - binary classification, 1 - Trues, 0 - False\nreq_str = 'text'\ncls_str = 'group'\n\n# The structure of the dictionary fiels, and filds which are drpoped during operations\ndictionary_fields = ['brand_id', 'brand', req_str]\ndictionary_dropped = ['brand_id', 'brand']\n\n# The frequency (weight) for brand words (uses for weight increasing of the brands, brand translations, etc...)\nweight_multiplicator = 32","metadata":{"cellId":"o36mha3ynjonfmz1fs1n6p","trusted":true},"outputs":[],"execution_count":988},{"cell_type":"code","source":"# Define the positive dataset\nprint(\"*** Define the positive dataset ***\")\n\ndataset_raw = pd.read_excel(class_file[key_value], header=None, names=[req_str], engine='openpyxl')\ndataset_raw[cls_str] = 1\nprint(\"Positive Dataset\")\nprint(dataset_raw.head(-4))\nprint(\"Positive Dataset shape: \", dataset_raw.shape)","metadata":{"cellId":"l1tslfrp5v8jx2h87kre9","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"*** Define the positive dataset ***\nPositive Dataset\n                               text  group\n0              кофе новогодняя ночь      1\n1               кофе мягкой обжарки      1\n2                     армпромсервис      1\n3                   кофе белый арап      1\n4     кофе в зернах бразилия купить      1\n...                             ...    ...\n7446        где купить молотый кофе      1\n7447       кофе растворимый в пачке      1\n7448                 кофе palombini      1\n7449              кубита торрефакто      1\n7450     кофе в зернах монтана кофе      1\n\n[7451 rows x 2 columns]\nPositive Dataset shape:  (7455, 2)\n"}],"execution_count":974},{"cell_type":"code","source":"# Define the negative dataset\nprint(\"*** Define the negative dataset ***\")\n\ncont_dataset = pd.DataFrame()\n\nfor key, value in class_file.items():\n    if key != key_value:\n        tmp = pd.read_excel(value, header=None, names=[req_str], engine='openpyxl')\n        tmp[cls_str] = 0\n        \n        print(f\"Size of {key}:\", tmp.shape)\n        \n        # Checking that your target dataset does not contain the fields from other sets\n        dataset_raw.drop(dataset_raw[dataset_raw[req_str].isin(tmp[req_str])].index, inplace=True)\n        print(f\"Positive dataset shape {dataset_raw.shape}, after duplication cleaning in {key_value} by fields from {key}\")\n        \n        # Add a new part to the negative dataset \n        cont_dataset = pd.concat([cont_dataset, tmp], sort=False)\n\n# Shafle cont_dataset\ncont_dataset = cont_dataset.sample(frac = 1).reset_index(drop=True)\n        \nprint(f\"Positive dataset shape {dataset_raw.shape}, after dublication cleaning in {key_value}\")\nprint(\"Negative set:\")\nprint(cont_dataset)\nprint(\"Size of the negative set:\", cont_dataset.shape)","metadata":{"cellId":"1q6eblyddcfhfsyo5dnb69","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"*** Define the negative dataset ***\nSize of zoo.xlsx: (69267, 2)\nPositive dataset shape (7455, 2), after duplication cleaning in coffee.xlsx by fields from zoo.xlsx\nSize of pampers.xlsx: (49175, 2)\nPositive dataset shape (7455, 2), after duplication cleaning in coffee.xlsx by fields from pampers.xlsx\nSize of toys.xlsx: (451274, 2)\nPositive dataset shape (7455, 2), after duplication cleaning in coffee.xlsx by fields from toys.xlsx\nPositive dataset shape (7455, 2), after dublication cleaning in coffee.xlsx\nNegative set:\n                                        text  group\n0                            собака на заказ      0\n1       купить подгузники хаггис элит софт 3      0\n2                      боевая голова игрушка      0\n3                        игрушка медведь 100      0\n4                            всё лего оружие      0\n...                                      ...    ...\n569711               ковер детский малиновый      0\n569712                          купить вулик      0\n569713                игрушка часы запускать      0\n569714          подъемный кран брудер отзывы      0\n569715       автоматические поилки для кошек      0\n\n[569716 rows x 2 columns]\nSize of the negative set: (569716, 2)\n"}],"execution_count":975},{"cell_type":"code","source":"# 4 \n# Let us define the train data set which we are going to use during our model fitting, \n# and the validation dataset for the following checking of the model.\n\nprint(\"*** Define train and validation datasetes ***\")\n\n# Train Dataset\ndf_train = pd.concat([\n    dataset_raw[:(round(dataset_raw.shape[0]*0.75))],\n    cont_dataset[:(round(cont_dataset.shape[0]*0.75))]\n]).sample(frac = 1).reset_index(drop=True)\n\n# Validation dataset\ndf_val = pd.concat([\n    dataset_raw[(round(dataset_raw.shape[0]*0.75)):],\n    cont_dataset[(round(cont_dataset.shape[0]*0.75)):]\n]).sample(frac = 1).reset_index(drop=True)\n\nprint(\"Sizes of our dataset before operations: \", dataset_raw.shape, cont_dataset.shape)\nprint(\"The dataset size for the model fitting: \", df_train.shape)\nprint(\"The dataset size for the model checking: \", df_val.shape)","metadata":{"cellId":"lcwf4myevs7831o6ng7lb","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"*** Define train and validation datasetes ***\nSizes of our dataset before operations:  (7455, 2) (569716, 2)\nThe dataset size for the model fitting:  (432878, 2)\nThe dataset size for the model checking:  (144293, 2)\n"}],"execution_count":989},{"cell_type":"code","source":"# 5 \n# Adding words from support dictionary \n# PLS check that the name of the support dictionary file is equal with \"dict_name\" value\n\nprint(\"*** Adding words from support dictionary ***\")\ndictionary = pd.DataFrame(columns=dictionary_fields)\n\nfor d_key, d_value in dictionary_files.items():\n    if d_key == dict_name:\n        tmp = pd.read_excel(d_value, names=dictionary_fields, engine='openpyxl')\n        tmp[cls_str] = 1\n        dictionary = dictionary.append(tmp, sort=False)\n\ndictionary = dictionary.drop(dictionary_dropped, axis = 1)\n\nprint(\"Dictionary dataset shape:\", dictionary.shape)\nprint(dictionary.head(-4))\n\nprint(\"Train dataset shape before dictionary adding:\", df_train.shape)\n\nfor _ in range(weight_multiplicator):\n    df_train = pd.concat([df_train, dictionary], sort=False)\n\ndf_train  = df_train.reset_index(drop=True)\n\nprint(\"Train dataset shape after dictionary adding:\", df_train.shape)","metadata":{"cellId":"z73f36deijkj3jowp8iqm","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"*** Adding words from support dictionary ***\nDictionary dataset shape: (1966, 2)\n               text  group\n0            вошеба    1.0\n1            Восеба    1.0\n2            Woseba    1.0\n3            восеба    1.0\n4            woseba    1.0\n...             ...    ...\n1957  нэ скафе голд    1.0\n1958    нескофеголд    1.0\n1959  нескафе  голд    1.0\n1960  не скафе голд    1.0\n1961        bourbon    1.0\n\n[1962 rows x 2 columns]\nTrain dataset shape before dictionary adding: (432878, 2)\nTrain dataset shape after dictionary adding: (495790, 2)\n"}],"execution_count":990},{"cell_type":"code","source":"# 6 Prepare X and Y for the model fitting\nprint(\"*** Prepare X and Y ***\")\n\n# Train\nx_train = df_train.drop([cls_str], axis = 1)\ny_train = df_train[cls_str]\nprint(\"Test X, Y shapes: \", x_train.shape, y_train.shape)\n\n# Validation\nx_val = df_val.drop([cls_str], axis = 1)\ny_val = df_val[cls_str]\n\nprint(\"Validation X, Y shapes: \", x_val.shape, y_val.shape)","metadata":{"cellId":"y27ny2thtdfsfu4rcxh5kk","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"*** Prepare X and Y ***\nTest X, Y shapes:  (495790, 1) (495790,)\nValidation X, Y shapes:  (144293, 1) (144293,)\n"}],"execution_count":991},{"cell_type":"code","source":"# 7 Prepare the Pipeline, vectoiriser and SGD classifier \nprint(\"*** Prepare the Pipeline, vectoiriser and SGD classifier ***\")\n\nsgd_ppl_clf = Pipeline([\n    ('tfidf', TfidfVectorizer(ngram_range=(1, 2))),\n    ('sgd_clf', SGDClassifier(\n        random_state=None,\n        class_weight=None,\n        loss='perceptron', \n        penalty='l2'\n    ))])\n\nprint(sgd_ppl_clf)","metadata":{"cellId":"lge2t73f8trrm1pgvlygx8","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"*** Prepare the Pipeline, vectoiriser and SGD classifier ***\nPipeline(memory=None,\n         steps=[('tfidf',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=True, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, strip_accents=None,\n                                 sublinear_tf=False,\n                                 token_pattern='...\n                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n                               early_stopping=False, epsilon=0.1, eta0=0.0,\n                               fit_intercept=True, l1_ratio=0.15,\n                               learning_rate='optimal', loss='perceptron',\n                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n                               penalty='l2', power_t=0.5, random_state=None,\n                               shuffle=True, tol=0.001, validation_fraction=0.1,\n                               verbose=0, warm_start=False))],\n         verbose=False)\n"}],"execution_count":992},{"cell_type":"code","source":"print(\"*** Fit SGD classifier  ***\")\nsgd_ppl_clf.fit(x_train[req_str], y_train)","metadata":{"cellId":"7tzmbqm5aib19eqt3wts","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"*** Fit SGD classifier  ***\n"},{"output_type":"display_data","data":{"text/plain":"Pipeline(memory=None,\n         steps=[('tfidf',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=True, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 2), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, strip_accents=None,\n                                 sublinear_tf=False,\n                                 token_pattern='...\n                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n                               early_stopping=False, epsilon=0.1, eta0=0.0,\n                               fit_intercept=True, l1_ratio=0.15,\n                               learning_rate='optimal', loss='perceptron',\n                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n                               penalty='l2', power_t=0.5, random_state=None,\n                               shuffle=True, tol=0.001, validation_fraction=0.1,\n                               verbose=0, warm_start=False))],\n         verbose=False)"},"metadata":{}}],"execution_count":993},{"cell_type":"markdown","source":"# 2 Check the model","metadata":{"cellId":"fwid75dg8f4quqw64qlq8"}},{"cell_type":"code","source":"print(\"*** Check the model by the validation data ***\")\n\npredicted_sgd = sgd_ppl_clf.predict(x_val[req_str])\nprint(metrics.classification_report(predicted_sgd, y_val))","metadata":{"cellId":"87yyesmirbkrn64f02ww","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"*** Check the model by the validation data ***\n              precision    recall  f1-score   support\n\n         0.0       1.00      1.00      1.00    142476\n         1.0       0.96      0.98      0.97      1817\n\n    accuracy                           1.00    144293\n   macro avg       0.98      0.99      0.99    144293\nweighted avg       1.00      1.00      1.00    144293\n\n"}],"execution_count":994},{"cell_type":"code","source":"print(\"*** Check and calculate the metrics ourselves ***\")\n\n# model prediction result\na_check = predicted_sgd.view()\n# Validation resuls  \nb_check = np.array(y_val)\n# проверим размерность\nprint(\"Check shapes of the prediction and Y validation:\", a_check.shape, b_check.shape)\n\n# True Negative Predicted - false, Real - false\nab_diff_tn = []\n# False Negative Predicted - false, Real - True\nab_diff_fn = []\n# False positive Predicted - True, Real - False\nab_diff_fp = []\n# True positive Predicted - True, Real - True\nab_diff_tp = []\n\nprint('')\nprint('******')\nprint(key_value)\n\nfor indx in range(len(a_check)):\n    if (a_check[indx] == True):\n        if (b_check[indx] == True):\n            ab_diff_tp.append(indx)\n        else:\n            ab_diff_fp.append(indx)\n    else:\n        if (b_check[indx] == True):\n            ab_diff_fn.append(indx)\n        else:\n            ab_diff_tn.append(indx)\n            \ntn =  len(ab_diff_tn)\nfn =  len(ab_diff_fn)\nfp =  len(ab_diff_fp)\ntp =  len(ab_diff_tp)\n\nprint(f\"True Negative:  {tn}  | False Positive:  {fp}\")\nprint(f\"False Negative: {fn}   | True Positive:  {tp}\")\n\nprint(f\"Precision = {tp} / ( {tp} + {fp} ) = {round(tp/(tp+fp), 2)}\")\nprint(f\"Recall = {tp} / ( {tp} + {fn} ) = {round(tp/(tp+fn), 2) }\")\n\nprint('')\nprint('******')\nprint(f\"Accurracy = {round(metrics.accuracy_score(a_check, b_check), 2) }\")\nprint(f\"F1 Score = {round(metrics.f1_score(a_check, b_check, average='weighted'), 2) }\")","metadata":{"cellId":"d8ktoinkzfbeqkhdalk8m","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"*** Check and calculate the metrics ourselves ***\nCheck shapes of the prediction and Y validation: (144293,) (144293,)\n\n******\ncoffee.xlsx\nTrue Negative:  142398  | False Positive:  31\nFalse Negative: 78   | True Positive:  1786\nPrecision = 1786 / ( 1786 + 31 ) = 0.98\nRecall = 1786 / ( 1786 + 78 ) = 0.96\n\n******\nAccurracy = 1.0\nF1 Score = 1.0\n"}],"execution_count":995},{"cell_type":"markdown","source":"# 3 Stream classification","metadata":{"cellId":"0dskjnuvyqbn60f7wodc0aj"}},{"cell_type":"code","source":"df_stream = pd.read_csv(pwd + '/content/stream/Поток_30К_уникальные.csv')\ndf_stream[\"QueryText\"] = df_stream[\"QueryText\"].str.replace('\\d+', '')\ndf_stream = df_stream.fillna('')\ndf_stream.head(2)","metadata":{"cellId":"cmxiysinc7kd0k41xsr59","trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"           QueryText\n0  стяжки fortisflex\n1      каэдэ косплей","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>QueryText</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>стяжки fortisflex</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>каэдэ косплей</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":996},{"cell_type":"code","source":"df = pd.DataFrame()\n\npredicted_stream = sgd_ppl_clf.predict(df_stream[\"QueryText\"])\n\ndf[\"Request\"] = df_stream[\"QueryText\"]\ndf[\"Predicted\"] = predicted_stream\ndf2 = df[df[\"Predicted\"]==True]\ndf2.to_csv(pwd + \"/content/ab_analyse/coffee_predictions.csv\")\ndf2","metadata":{"cellId":"wggndrcxxbat7ryyhdmix","trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"                                                 Request  Predicted\n26                       Unlimited Nothing Like The Rain        1.0\n51      соляной шоколадно-кофейный скраб для тела массаж        1.0\n162                                   диара капсулы цена        1.0\n322                     как сделать фокус с колодой карт        1.0\n332          письмо Минэкономразвития России от .. № Ди-        1.0\n...                                                  ...        ...\n29581                           black desert фотофильтр         1.0\n29620                                 Grand+Teft+Auto+IV        1.0\n29628                   Артозакс в капсулах АлтайСашемед        1.0\n29667                        первородный гадальная карта        1.0\n29723  модулятор бесконтактный мб - содержание драгме...        1.0\n\n[665 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Request</th>\n      <th>Predicted</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>26</th>\n      <td>Unlimited Nothing Like The Rain</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>соляной шоколадно-кофейный скраб для тела массаж</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>162</th>\n      <td>диара капсулы цена</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>322</th>\n      <td>как сделать фокус с колодой карт</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>332</th>\n      <td>письмо Минэкономразвития России от .. № Ди-</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>29581</th>\n      <td>black desert фотофильтр</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>29620</th>\n      <td>Grand+Teft+Auto+IV</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>29628</th>\n      <td>Артозакс в капсулах АлтайСашемед</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>29667</th>\n      <td>первородный гадальная карта</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>29723</th>\n      <td>модулятор бесконтактный мб - содержание драгме...</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>665 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":997},{"cell_type":"code","source":"","metadata":{"cellId":"sn2f1que1lycgqluziiwe"},"outputs":[],"execution_count":null}]}