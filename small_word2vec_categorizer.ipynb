{"nbformat":4,"nbformat_minor":4,"metadata":{"colab":{"name":"SmallCategorising 3","provenance":[],"collapsed_sections":[],"history_visible":true},"kernelspec":{"name":"python3","display_name":"Yandex DataSphere Kernel","language":"python"},"language_info":{"codemirror_mode":{"version":3,"name":"ipython"},"mimetype":"text/x-python","version":"3.7.7","file_extension":".py","pygments_lexer":"ipython3","nbconvert_exporter":"python","name":"python"},"notebookId":"a8971072-9d0a-4905-80b9-57c3c2d534be"},"cells":[{"cell_type":"markdown","source":"# 1 Preparing","metadata":{"id":"pWoBMyZkLXfr","cellId":"u9sjy7wmfkgsraea8jj80j"}},{"cell_type":"code","source":"import os\nfrom gensim import models\nimport pandas as pd","metadata":{"cellId":"mxkvide44kne8wnz011zig","trusted":true},"outputs":[],"execution_count":9},{"cell_type":"code","source":"import nltk\nfrom nltk.corpus import stopwords\nfrom string import punctuation","metadata":{"cellId":"4fgm29z63iqt7s7zwba63d","trusted":true},"outputs":[],"execution_count":111},{"cell_type":"code","source":"from gensim.models import KeyedVectors\nimport numpy as np","metadata":{"cellId":"ei642mdanqiaecg9iebi","trusted":true},"outputs":[],"execution_count":176},{"cell_type":"code","source":"dataset_files = {}\ndictionary_files = {}\n\n# Target dataset (which is used for the true classification)\nkey_dataset = \"coffee.xlsx\"\ndict_name = 'coffee_dict.xlsx'\n\n# *** Datasets ***\ndataset_path = '/home/jupyter/work/resources/content/datasets/'\ndict_path = '/home/jupyter/work/resources/content/dictionaries/'\n\n# Dataset structure - used for the source datasets fields\nreq_str = 'text'","metadata":{"cellId":"8zgpmtuxd7d6pg3i3ixub","trusted":true},"outputs":[],"execution_count":148},{"cell_type":"markdown","source":"# 2 Load data","metadata":{"cellId":"wla2us9pcb6g88oad54hh"}},{"cell_type":"code","source":"# *** Datasets loading***\nfor entry in os.listdir(dataset_path):\n    if os.path.isfile(os.path.join(dataset_path, entry)):\n        dataset_files[entry] = dataset_path + entry\n        \n# *** Loadingf of dictionaries with brands and support words ***\nfor entry in os.listdir(dataset_path):\n    if os.path.isfile(os.path.join(dataset_path, entry)):\n        dictionary_files[entry] = dataset_path + entry","metadata":{"cellId":"p5401seyy7s2j62w4941rv","trusted":true},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Define the positive dataset\npositive_dataset = pd.read_excel(dataset_files[key_dataset], header=None, names=[req_str], engine='openpyxl')\npositive_dataset['label'] = 1\n\n# Define the negative dataset\n\ncont_dataset = pd.DataFrame()\n\nfor key, value in dataset_files.items():\n    if key != key_dataset:\n        tmp = pd.read_excel(value, header=None, names=[req_str], engine='openpyxl')\n        tmp['label'] = 0\n        \n        # Checking that your target dataset does not contain the fields from other sets\n        positive_dataset.drop(positive_dataset[positive_dataset[req_str].isin(tmp[req_str])].index, inplace=True)\n        \n        # Add a new part to the negative dataset \n        cont_dataset = pd.concat([cont_dataset, tmp], sort=False)\n\ncont_dataset = cont_dataset.sample(frac = 1).reset_index(drop=True)\n\n# Let us define the train data set which we are going to use during our model fitting, \n# and the validation dataset for the following checking of the model.\n\n# Train Dataset\ndf_train = pd.concat([\n    positive_dataset[:(round(positive_dataset.shape[0]*0.75))],\n    cont_dataset[:(round(cont_dataset.shape[0]*0.75))]\n]).sample(frac = 1).reset_index(drop=True)\n\n# Validation dataset\ndf_val = pd.concat([\n    positive_dataset[(round(positive_dataset.shape[0]*0.75)):],\n    cont_dataset[(round(cont_dataset.shape[0]*0.75)):]\n]).sample(frac = 1).reset_index(drop=True)","metadata":{"cellId":"bqnigdroa97gkzbkzp42r","trusted":true},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"# 3 Preprocess data analysing","metadata":{"cellId":"s6itt8u25gnpyno5kpjb9"}},{"cell_type":"code","source":"print(\"------\")\nprint(\"Basic statistics\")\nprint(\"\")\nprint(\"Train shape: \", df_train.shape)\nprint(\"Validation shape: \", df_val.shape)\ntrue_label = (df_train.label.value_counts() / df_train.shape[0])[1]\nfalse_label = (df_train.label.value_counts() / df_train.shape[0])[0]\nprint(f\"Class distribution:\\n True = {round(true_label*100, 2)}%,\\n False = {round(false_label*100, 2)}%\")\nprint(\"\")\nprint(\"------\")\nprint(\"Label basic statistics\")\nprint(\"\")\nprint(df_train['label'].value_counts())\nprint(\"\")\nprint(\"------\")\nprint(\"Text basic statistics\")\nprint(\"\")\nprint('Total unique reqests counts:', len(df_train[req_str].unique()))\nprint(\"Mean amount of words in sentences (train dataset): \", df_train[req_str].str.split().map(len).mean())\nprint(\"Mean chars amount in sentences (train dataset): \", df_train[req_str].str.len().mean())\nprint(\"Max amount of words in sentences (train dataset): \", df_train[req_str].str.split().map(len).max())\nprint(\"Max chars amount in sentences (train dataset): \", df_train[req_str].str.len().max())\nprint(\"Mean amount of words in sentences (validation dataset): \", df_val[req_str].str.split().map(len).mean())\nprint(\"Mean chars amount in sentences (validation dataset): \", df_val[req_str].str.len().mean())\nprint(\"Max amount of words in sentences (validation dataset): \", df_val[req_str].str.split().map(len).max())\nprint(\"Max chars amount in sentences (validation dataset): \", df_val[req_str].str.len().max())\nprint(\"\")\nprint(\"------\")","metadata":{"cellId":"nr948hoeo7lww53vasf4e","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"------\nBasic statistics\n\nTrain shape:  (432878, 2)\nValidation shape:  (144293, 2)\nClass distribution:\n True = 1.29%,\n False = 98.71%\n\n------\nLabel basic statistics\n\n0    427287\n1      5591\nName: label, dtype: int64\n\n------\nText basic statistics\n\nTotal unique reqests counts: 432731\nMean amount of words in sentences (train dataset):  3.571847033113256\nMean chars amount in sentences (train dataset):  24.173413756300853\nMax amount of words in sentences (train dataset):  16\nMax chars amount in sentences (train dataset):  100\nMean amount of words in sentences (validation dataset):  3.569979139667205\nMean chars amount in sentences (validation dataset):  24.15932858835841\nMax amount of words in sentences (validation dataset):  15\nMax chars amount in sentences (validation dataset):  95\n\n------\n"}],"execution_count":98},{"cell_type":"code","source":"df_train[req_str].str.split().map(len).hist().set_title('Amount of words in sentences')\ndf_val[req_str].str.split().map(len).hist()","metadata":{"cellId":"mb7zvvz1cwct9v8sw6h2l","trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"<AxesSubplot:title={'center':'Amount of words in sentences'}>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}],"execution_count":96},{"cell_type":"code","source":"df_train[req_str].str.len().hist().set_title('Chars amount in sentences')\ndf_val[req_str].str.len().hist()","metadata":{"cellId":"x8pzq0cbtmjhgfo5gvx1g","trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"<AxesSubplot:title={'center':'Chars amount in sentences'}>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}],"execution_count":99},{"cell_type":"code","source":"df_train.isnull().values.any(), df_val.isnull().values.any(),","metadata":{"cellId":"i5iqhf49r6ij9kwc3f6648","trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"(False, False)"},"metadata":{}}],"execution_count":101},{"cell_type":"markdown","source":"# 4 Preprocess data","metadata":{"cellId":"a7r5cpp0mk4imj7j59ilym"}},{"cell_type":"code","source":"russian_stopwords = set(stopwords.words(\"russian\"))\n\ndef preprocess_text(text):\n    #tokens = mystem.lemmatize(text.lower())\n    tokens = nltk.tokenize.word_tokenize(text.lower())\n    tokens = [token for token in tokens if token not in russian_stopwords\\\n              and token != \" \" \\\n              and token.strip() not in punctuation]\n    \n    text = \" \".join(tokens)\n    \n    return text\n\ndef preprocess_tokens(text):\n    tokens = nltk.tokenize.word_tokenize(text.lower())\n    tokens = [token for token in tokens if token not in russian_stopwords\\\n              and token != \" \" \\\n              and token.strip() not in punctuation]\n    \n    return tokens\n\ndf_train['tokens'] = df_train[req_str].apply(preprocess_tokens)\ndf_val['tokens'] = df_train[req_str].apply(preprocess_tokens)\ndf_train['cleaned_text'] = df_train[req_str].apply(preprocess_text)\ndf_val['cleaned_text'] = df_val[req_str].apply(preprocess_text)","metadata":{"cellId":"qhqgxmyy77z73ssb77go","trusted":true},"outputs":[],"execution_count":256},{"cell_type":"code","source":"df_train","metadata":{"cellId":"5e5bijtcq7gd2id8tlp54d","trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"                                                 text  label  \\\n0                              наборы фигурок миньоны      0   \n1                                     bandai megazord      0   \n2                               чайный домик ниндзяго      0   \n3                       игрушки брудер мусоровоз цена      0   \n4       кукла shibajuku girls купить интернет магазин      0   \n...                                               ...    ...   \n432873   электронные игры для девочек холодное сердце      0   \n432874             паровозик для детей игрушка купить      0   \n432875                         памперсы кораблик цена      0   \n432876                            игрушка мазда демио      0   \n432877                  плюшевый мишка путешественник      0   \n\n                                         cleaned_text  \\\n0                              наборы фигурок миньоны   \n1                                     bandai megazord   \n2                               чайный домик ниндзяго   \n3                       игрушки брудер мусоровоз цена   \n4       кукла shibajuku girls купить интернет магазин   \n...                                               ...   \n432873       электронные игры девочек холодное сердце   \n432874                 паровозик детей игрушка купить   \n432875                         памперсы кораблик цена   \n432876                            игрушка мазда демио   \n432877                  плюшевый мишка путешественник   \n\n                                                   tokens  \n0                              [наборы, фигурок, миньоны]  \n1                                      [bandai, megazord]  \n2                               [чайный, домик, ниндзяго]  \n3                      [игрушки, брудер, мусоровоз, цена]  \n4       [кукла, shibajuku, girls, купить, интернет, ма...  \n...                                                   ...  \n432873     [электронные, игры, девочек, холодное, сердце]  \n432874                [паровозик, детей, игрушка, купить]  \n432875                         [памперсы, кораблик, цена]  \n432876                            [игрушка, мазда, демио]  \n432877                  [плюшевый, мишка, путешественник]  \n\n[432878 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n      <th>cleaned_text</th>\n      <th>tokens</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>наборы фигурок миньоны</td>\n      <td>0</td>\n      <td>наборы фигурок миньоны</td>\n      <td>[наборы, фигурок, миньоны]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>bandai megazord</td>\n      <td>0</td>\n      <td>bandai megazord</td>\n      <td>[bandai, megazord]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>чайный домик ниндзяго</td>\n      <td>0</td>\n      <td>чайный домик ниндзяго</td>\n      <td>[чайный, домик, ниндзяго]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>игрушки брудер мусоровоз цена</td>\n      <td>0</td>\n      <td>игрушки брудер мусоровоз цена</td>\n      <td>[игрушки, брудер, мусоровоз, цена]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>кукла shibajuku girls купить интернет магазин</td>\n      <td>0</td>\n      <td>кукла shibajuku girls купить интернет магазин</td>\n      <td>[кукла, shibajuku, girls, купить, интернет, ма...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>432873</th>\n      <td>электронные игры для девочек холодное сердце</td>\n      <td>0</td>\n      <td>электронные игры девочек холодное сердце</td>\n      <td>[электронные, игры, девочек, холодное, сердце]</td>\n    </tr>\n    <tr>\n      <th>432874</th>\n      <td>паровозик для детей игрушка купить</td>\n      <td>0</td>\n      <td>паровозик детей игрушка купить</td>\n      <td>[паровозик, детей, игрушка, купить]</td>\n    </tr>\n    <tr>\n      <th>432875</th>\n      <td>памперсы кораблик цена</td>\n      <td>0</td>\n      <td>памперсы кораблик цена</td>\n      <td>[памперсы, кораблик, цена]</td>\n    </tr>\n    <tr>\n      <th>432876</th>\n      <td>игрушка мазда демио</td>\n      <td>0</td>\n      <td>игрушка мазда демио</td>\n      <td>[игрушка, мазда, демио]</td>\n    </tr>\n    <tr>\n      <th>432877</th>\n      <td>плюшевый мишка путешественник</td>\n      <td>0</td>\n      <td>плюшевый мишка путешественник</td>\n      <td>[плюшевый, мишка, путешественник]</td>\n    </tr>\n  </tbody>\n</table>\n<p>432878 rows × 4 columns</p>\n</div>"},"metadata":{}}],"execution_count":257},{"cell_type":"code","source":"df_val","metadata":{"cellId":"xua5vdsn4wlvaptsgf5d3","trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"                                    text  label  \\\n0           купить игрушечная мастерская      0   \n1                      игрушка chericole      0   \n2            растения для акватеррариума      0   \n3                    kami l espresso oro      1   \n4                      minecraft steve 1      0   \n...                                  ...    ...   \n144288  корм уценка уцененный срок кошек      0   \n144289         фиолетовая собака мультик      0   \n144290          интерактивный щенок гоша      0   \n144291             набор техники военный      0   \n144292                лего вездеход 2017      0   \n\n                            cleaned_text  \\\n0           купить игрушечная мастерская   \n1                      игрушка chericole   \n2                растения акватеррариума   \n3                    kami l espresso oro   \n4                      minecraft steve 1   \n...                                  ...   \n144288  корм уценка уцененный срок кошек   \n144289         фиолетовая собака мультик   \n144290          интерактивный щенок гоша   \n144291             набор техники военный   \n144292                лего вездеход 2017   \n\n                                                   tokens  \n0                              [наборы, фигурок, миньоны]  \n1                                      [bandai, megazord]  \n2                               [чайный, домик, ниндзяго]  \n3                      [игрушки, брудер, мусоровоз, цена]  \n4       [кукла, shibajuku, girls, купить, интернет, ма...  \n...                                                   ...  \n144288  [детский, набор, строительных, инструментов, м...  \n144289                  [купить, динозавра, плео, москве]  \n144290         [закупка, памперсов, оптом, производителя]  \n144291                            [кукла, пупс, danielle]  \n144292                         [плотность, дерева, венге]  \n\n[144293 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n      <th>cleaned_text</th>\n      <th>tokens</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>купить игрушечная мастерская</td>\n      <td>0</td>\n      <td>купить игрушечная мастерская</td>\n      <td>[наборы, фигурок, миньоны]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>игрушка chericole</td>\n      <td>0</td>\n      <td>игрушка chericole</td>\n      <td>[bandai, megazord]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>растения для акватеррариума</td>\n      <td>0</td>\n      <td>растения акватеррариума</td>\n      <td>[чайный, домик, ниндзяго]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>kami l espresso oro</td>\n      <td>1</td>\n      <td>kami l espresso oro</td>\n      <td>[игрушки, брудер, мусоровоз, цена]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>minecraft steve 1</td>\n      <td>0</td>\n      <td>minecraft steve 1</td>\n      <td>[кукла, shibajuku, girls, купить, интернет, ма...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>144288</th>\n      <td>корм уценка уцененный срок кошек</td>\n      <td>0</td>\n      <td>корм уценка уцененный срок кошек</td>\n      <td>[детский, набор, строительных, инструментов, м...</td>\n    </tr>\n    <tr>\n      <th>144289</th>\n      <td>фиолетовая собака мультик</td>\n      <td>0</td>\n      <td>фиолетовая собака мультик</td>\n      <td>[купить, динозавра, плео, москве]</td>\n    </tr>\n    <tr>\n      <th>144290</th>\n      <td>интерактивный щенок гоша</td>\n      <td>0</td>\n      <td>интерактивный щенок гоша</td>\n      <td>[закупка, памперсов, оптом, производителя]</td>\n    </tr>\n    <tr>\n      <th>144291</th>\n      <td>набор техники военный</td>\n      <td>0</td>\n      <td>набор техники военный</td>\n      <td>[кукла, пупс, danielle]</td>\n    </tr>\n    <tr>\n      <th>144292</th>\n      <td>лего вездеход 2017</td>\n      <td>0</td>\n      <td>лего вездеход 2017</td>\n      <td>[плотность, дерева, венге]</td>\n    </tr>\n  </tbody>\n</table>\n<p>144293 rows × 4 columns</p>\n</div>"},"metadata":{}}],"execution_count":258},{"cell_type":"code","source":"def cnt_uniq(col):\n    count = set()\n    for line in col:\n        count |= set(line)\n    return len(count)\n\nprint(\"------\")\nprint(\"Unique words in df_train.tokens: \", cnt_uniq(df_train.tokens))\nprint(\"Unique words in df_val.tokens: \", cnt_uniq(df_val.tokens))\nprint(\"------\")","metadata":{"cellId":"hom2apozk7oqs87bh3v0cg","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"------\nUnique words in df_train.tokens:  63541\nUnique words in df_val.tokens:  36983\n------\n"}],"execution_count":147},{"cell_type":"markdown","source":"# 5 Taking pre-trained word2vec or fastText embeddings and vectorize the data","metadata":{"cellId":"f8nv3ryhyrgxea0cm7g24"}},{"cell_type":"code","source":"# https://rusvectores.org/ru/models/\n# for the ferst approach let us take geowac_tokens_none_fasttextskipgram_300_5_2020\n# http://vectors.nlpl.eu/repository/20/214.zip\n%time\n!wget -c 'http://vectors.nlpl.eu/repository/20/214.zip' --directory-prefix='content/models'","metadata":{"cellId":"wxohthqo1wpdmrujjsxrsu","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"CPU times: user 0 ns, sys: 0 ns, total: 0 ns\nWall time: 10 µs\n--2021-09-18 18:08:05--  http://vectors.nlpl.eu/repository/20/214.zip\nResolving vectors.nlpl.eu (vectors.nlpl.eu)... 129.240.189.181\nConnecting to vectors.nlpl.eu (vectors.nlpl.eu)|129.240.189.181|:80... connected.\nHTTP request sent, awaiting response... 416 Requested Range Not Satisfiable\n\n    The file is already fully retrieved; nothing to do.\n\n"}],"execution_count":154},{"cell_type":"code","source":"!unzip 'content/models/214.zip' -d 'content/models/214'","metadata":{"cellId":"ywak6cykl9skv3i0qq5nf","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"Archive:  content/models/214.zip\n  inflating: content/models/214/meta.json  \n  inflating: content/models/214/model.model  \n  inflating: content/models/214/model.model.vectors_ngrams.npy  \n  inflating: content/models/214/model.model.vectors.npy  \n  inflating: content/models/214/model.model.vectors_vocab.npy  \n  inflating: content/models/214/README  \n"}],"execution_count":153},{"cell_type":"code","source":"w2v_model = KeyedVectors.load('content/models/214/model.model')","metadata":{"cellId":"bw2qa59fktwsske10xik1l","trusted":true},"outputs":[],"execution_count":168},{"cell_type":"code","source":"print(w2v_model.most_similar('teacher'))\n# Output = [('headteacher', 0.8075869083404541), ('schoolteacher', 0.7955552339553833), ('teachers', 0.733420729637146), ('teaches', 0.6839243173599243), ('meacher', 0.6825737357139587), ('teach', 0.6285147070884705), ('taught', 0.6244685649871826), ('teaching', 0.6199781894683838), ('schoolmaster', 0.6037642955780029), ('lessons', 0.5812176465988159)]\n\nprint(w2v_model.similarity('teacher', 'teaches'))\n# Output = 0.683924396754","metadata":{"cellId":"kses406a5cakvv6t4rzkjs","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"[('teachers', 0.8642313480377197), ('teach', 0.8517892360687256), ('teaching', 0.804637610912323), ('preacher', 0.745186984539032), ('students', 0.7032978534698486), ('grammar', 0.6876246333122253), ('education', 0.6809180378913879), ('language', 0.6790481805801392), ('learning', 0.6770287752151489), ('lessons', 0.6763585805892944)]\n0.86742723\n"}],"execution_count":169},{"cell_type":"markdown","source":"# 6 Use pretrained embeddings as features to a classifier","metadata":{"cellId":"oo6asrrpoxo286sukead0v"}},{"cell_type":"code","source":"def avg_feature_vector(sentence, model, num_features):\n    words = sentence.split()\n    feature_vec = np.zeros((num_features,),dtype=\"float32\")\n    i=0\n    for word in words:\n        try:\n            feature_vec = np.add(feature_vec, model[word])\n        except KeyError as error:\n            feature_vec \n            i = i + 1\n    if len(words) > 0:\n        feature_vec = np.divide(feature_vec, len(words)- i)\n    return feature_vec","metadata":{"cellId":"sl7v5n839befepolaib6a","trusted":true},"outputs":[],"execution_count":298},{"cell_type":"code","source":"#!g1.1\nx_train = pd.DataFrame()\nword2vec_train = np.zeros((len(df_train.index), 300),dtype=\"float32\")\n\nfor i in range(len(df_train.index)):\n    word2vec_train[i] = avg_feature_vector(df_train[\"cleaned_text\"][i], w2v_model, 300)\n\nnames_df = pd.DataFrame(data=word2vec_train)\nx_train = pd.concat([x_train, names_df], axis=1)\ny_train = df_train.label\nx_train","metadata":{"cellId":"c02rhivy3patvyblpm18qq","trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"             0         1         2         3         4         5         6    \\\n0      -0.066713  0.082942 -0.010662 -0.111803 -0.079457 -0.434792 -0.106997   \n1      -0.261288 -0.060402  0.342453 -0.311789  0.115866 -0.059775 -0.135599   \n2       0.038728  0.003996 -0.049787  0.024954 -0.254933 -0.251597 -0.116762   \n3      -0.124907 -0.087466 -0.043224 -0.055114 -0.036133 -0.206226 -0.301870   \n4      -0.262756 -0.041589  0.175519  0.002730 -0.240115 -0.319160 -0.015173   \n...          ...       ...       ...       ...       ...       ...       ...   \n432873 -0.144212  0.002015  0.129216 -0.152031 -0.172071 -0.294749 -0.044193   \n432874 -0.069521  0.000091 -0.022347 -0.030287 -0.292700 -0.220955 -0.120907   \n432875  0.027515 -0.208212  0.069029  0.103831 -0.262487 -0.219450 -0.121879   \n432876 -0.100114  0.194142  0.168734 -0.223016 -0.136961 -0.139871 -0.238558   \n432877 -0.107574  0.091272  0.006469 -0.034822 -0.278232 -0.214132  0.041134   \n\n             7         8         9    ...       290       291       292  \\\n0       0.365572 -0.149611 -0.018134  ... -0.069665  0.188845 -0.223124   \n1       0.022243  0.199407  0.170820  ...  0.032028 -0.023515  0.024769   \n2       0.250436 -0.207230  0.167426  ...  0.023190 -0.174606  0.019169   \n3       0.167975  0.116403  0.245811  ... -0.101062  0.115150 -0.111792   \n4       0.225068 -0.110758  0.231244  ... -0.034381 -0.000137 -0.016929   \n...          ...       ...       ...  ...       ...       ...       ...   \n432873  0.181058  0.197308  0.142886  ...  0.029808 -0.065910 -0.049157   \n432874  0.198400  0.074411  0.084859  ... -0.050527  0.178038  0.044302   \n432875  0.072449 -0.045080  0.267747  ...  0.084002  0.098646 -0.044730   \n432876  0.264664  0.010691  0.230914  ... -0.444528  0.055486 -0.071525   \n432877  0.304807 -0.137219  0.145239  ... -0.202056 -0.309483  0.060729   \n\n             293       294       295       296       297       298       299  \n0       0.251621  0.090919  0.059522  0.032352 -0.067513  0.058853 -0.065847  \n1       0.278460 -0.016381  0.322340 -0.243902 -0.020962 -0.312346 -0.036781  \n2       0.063979  0.055845 -0.007685  0.137719  0.047505  0.051777 -0.226418  \n3       0.020151  0.151601  0.222682  0.039344 -0.133292 -0.055217 -0.013471  \n4       0.117933  0.150310  0.066467 -0.107601 -0.088795 -0.293791  0.092952  \n...          ...       ...       ...       ...       ...       ...       ...  \n432873  0.030863 -0.069495 -0.054453  0.180123 -0.051211 -0.154920 -0.075380  \n432874  0.031576  0.018763  0.211343  0.130179 -0.100829 -0.048994 -0.099164  \n432875 -0.046645  0.323528  0.439951  0.058484 -0.044691 -0.102957  0.039338  \n432876  0.176366 -0.055109  0.287983  0.074734 -0.249084 -0.217787 -0.182936  \n432877  0.006307  0.108528  0.292320 -0.203118  0.102562 -0.084775  0.054203  \n\n[432878 rows x 300 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>290</th>\n      <th>291</th>\n      <th>292</th>\n      <th>293</th>\n      <th>294</th>\n      <th>295</th>\n      <th>296</th>\n      <th>297</th>\n      <th>298</th>\n      <th>299</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.066713</td>\n      <td>0.082942</td>\n      <td>-0.010662</td>\n      <td>-0.111803</td>\n      <td>-0.079457</td>\n      <td>-0.434792</td>\n      <td>-0.106997</td>\n      <td>0.365572</td>\n      <td>-0.149611</td>\n      <td>-0.018134</td>\n      <td>...</td>\n      <td>-0.069665</td>\n      <td>0.188845</td>\n      <td>-0.223124</td>\n      <td>0.251621</td>\n      <td>0.090919</td>\n      <td>0.059522</td>\n      <td>0.032352</td>\n      <td>-0.067513</td>\n      <td>0.058853</td>\n      <td>-0.065847</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.261288</td>\n      <td>-0.060402</td>\n      <td>0.342453</td>\n      <td>-0.311789</td>\n      <td>0.115866</td>\n      <td>-0.059775</td>\n      <td>-0.135599</td>\n      <td>0.022243</td>\n      <td>0.199407</td>\n      <td>0.170820</td>\n      <td>...</td>\n      <td>0.032028</td>\n      <td>-0.023515</td>\n      <td>0.024769</td>\n      <td>0.278460</td>\n      <td>-0.016381</td>\n      <td>0.322340</td>\n      <td>-0.243902</td>\n      <td>-0.020962</td>\n      <td>-0.312346</td>\n      <td>-0.036781</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.038728</td>\n      <td>0.003996</td>\n      <td>-0.049787</td>\n      <td>0.024954</td>\n      <td>-0.254933</td>\n      <td>-0.251597</td>\n      <td>-0.116762</td>\n      <td>0.250436</td>\n      <td>-0.207230</td>\n      <td>0.167426</td>\n      <td>...</td>\n      <td>0.023190</td>\n      <td>-0.174606</td>\n      <td>0.019169</td>\n      <td>0.063979</td>\n      <td>0.055845</td>\n      <td>-0.007685</td>\n      <td>0.137719</td>\n      <td>0.047505</td>\n      <td>0.051777</td>\n      <td>-0.226418</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.124907</td>\n      <td>-0.087466</td>\n      <td>-0.043224</td>\n      <td>-0.055114</td>\n      <td>-0.036133</td>\n      <td>-0.206226</td>\n      <td>-0.301870</td>\n      <td>0.167975</td>\n      <td>0.116403</td>\n      <td>0.245811</td>\n      <td>...</td>\n      <td>-0.101062</td>\n      <td>0.115150</td>\n      <td>-0.111792</td>\n      <td>0.020151</td>\n      <td>0.151601</td>\n      <td>0.222682</td>\n      <td>0.039344</td>\n      <td>-0.133292</td>\n      <td>-0.055217</td>\n      <td>-0.013471</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.262756</td>\n      <td>-0.041589</td>\n      <td>0.175519</td>\n      <td>0.002730</td>\n      <td>-0.240115</td>\n      <td>-0.319160</td>\n      <td>-0.015173</td>\n      <td>0.225068</td>\n      <td>-0.110758</td>\n      <td>0.231244</td>\n      <td>...</td>\n      <td>-0.034381</td>\n      <td>-0.000137</td>\n      <td>-0.016929</td>\n      <td>0.117933</td>\n      <td>0.150310</td>\n      <td>0.066467</td>\n      <td>-0.107601</td>\n      <td>-0.088795</td>\n      <td>-0.293791</td>\n      <td>0.092952</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>432873</th>\n      <td>-0.144212</td>\n      <td>0.002015</td>\n      <td>0.129216</td>\n      <td>-0.152031</td>\n      <td>-0.172071</td>\n      <td>-0.294749</td>\n      <td>-0.044193</td>\n      <td>0.181058</td>\n      <td>0.197308</td>\n      <td>0.142886</td>\n      <td>...</td>\n      <td>0.029808</td>\n      <td>-0.065910</td>\n      <td>-0.049157</td>\n      <td>0.030863</td>\n      <td>-0.069495</td>\n      <td>-0.054453</td>\n      <td>0.180123</td>\n      <td>-0.051211</td>\n      <td>-0.154920</td>\n      <td>-0.075380</td>\n    </tr>\n    <tr>\n      <th>432874</th>\n      <td>-0.069521</td>\n      <td>0.000091</td>\n      <td>-0.022347</td>\n      <td>-0.030287</td>\n      <td>-0.292700</td>\n      <td>-0.220955</td>\n      <td>-0.120907</td>\n      <td>0.198400</td>\n      <td>0.074411</td>\n      <td>0.084859</td>\n      <td>...</td>\n      <td>-0.050527</td>\n      <td>0.178038</td>\n      <td>0.044302</td>\n      <td>0.031576</td>\n      <td>0.018763</td>\n      <td>0.211343</td>\n      <td>0.130179</td>\n      <td>-0.100829</td>\n      <td>-0.048994</td>\n      <td>-0.099164</td>\n    </tr>\n    <tr>\n      <th>432875</th>\n      <td>0.027515</td>\n      <td>-0.208212</td>\n      <td>0.069029</td>\n      <td>0.103831</td>\n      <td>-0.262487</td>\n      <td>-0.219450</td>\n      <td>-0.121879</td>\n      <td>0.072449</td>\n      <td>-0.045080</td>\n      <td>0.267747</td>\n      <td>...</td>\n      <td>0.084002</td>\n      <td>0.098646</td>\n      <td>-0.044730</td>\n      <td>-0.046645</td>\n      <td>0.323528</td>\n      <td>0.439951</td>\n      <td>0.058484</td>\n      <td>-0.044691</td>\n      <td>-0.102957</td>\n      <td>0.039338</td>\n    </tr>\n    <tr>\n      <th>432876</th>\n      <td>-0.100114</td>\n      <td>0.194142</td>\n      <td>0.168734</td>\n      <td>-0.223016</td>\n      <td>-0.136961</td>\n      <td>-0.139871</td>\n      <td>-0.238558</td>\n      <td>0.264664</td>\n      <td>0.010691</td>\n      <td>0.230914</td>\n      <td>...</td>\n      <td>-0.444528</td>\n      <td>0.055486</td>\n      <td>-0.071525</td>\n      <td>0.176366</td>\n      <td>-0.055109</td>\n      <td>0.287983</td>\n      <td>0.074734</td>\n      <td>-0.249084</td>\n      <td>-0.217787</td>\n      <td>-0.182936</td>\n    </tr>\n    <tr>\n      <th>432877</th>\n      <td>-0.107574</td>\n      <td>0.091272</td>\n      <td>0.006469</td>\n      <td>-0.034822</td>\n      <td>-0.278232</td>\n      <td>-0.214132</td>\n      <td>0.041134</td>\n      <td>0.304807</td>\n      <td>-0.137219</td>\n      <td>0.145239</td>\n      <td>...</td>\n      <td>-0.202056</td>\n      <td>-0.309483</td>\n      <td>0.060729</td>\n      <td>0.006307</td>\n      <td>0.108528</td>\n      <td>0.292320</td>\n      <td>-0.203118</td>\n      <td>0.102562</td>\n      <td>-0.084775</td>\n      <td>0.054203</td>\n    </tr>\n  </tbody>\n</table>\n<p>432878 rows × 300 columns</p>\n</div>"},"metadata":{}}],"execution_count":299},{"cell_type":"code","source":"#!g1.1\nx_val = pd.DataFrame()\nword2vec_val = np.zeros((len(df_val.index), 300),dtype=\"float32\")\n\nfor i in range(len(df_val.index)):\n    word2vec_val[i] = avg_feature_vector(df_val[\"cleaned_text\"][i], w2v_model, 300)\n\nnames_df = pd.DataFrame(data=word2vec_val)\nx_val = pd.concat([x_val, names_df], axis=1)\ny_val = df_val.label\nx_val","metadata":{"cellId":"ufs13qin3detrnf1yssnfj","trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"             0         1         2         3         4         5         6    \\\n0      -0.215482  0.056077  0.215897 -0.039115 -0.250837 -0.415031 -0.101325   \n1      -0.279157 -0.057534  0.076047 -0.177353  0.113635 -0.216639  0.000805   \n2      -0.160039  0.252769  0.195136  0.229320 -0.405540 -0.110455 -0.073409   \n3      -0.453910 -0.089990  0.237365 -0.084725 -0.169180 -0.238084  0.099591   \n4      -0.048142  0.044558  0.000380 -0.095190  0.029367 -0.226655  0.159691   \n...          ...       ...       ...       ...       ...       ...       ...   \n144288 -0.339769 -0.107381  0.009420  0.045568 -0.118220 -0.078068 -0.028155   \n144289 -0.293207 -0.095126 -0.027711 -0.098639 -0.409341 -0.207911  0.046775   \n144290  0.082674  0.141088 -0.100725  0.057958 -0.141860 -0.138624  0.151382   \n144291 -0.259409  0.091483  0.181957  0.074490 -0.042760 -0.090822  0.177005   \n144292  0.002290  0.171757  0.084544  0.020463 -0.233254 -0.198676  0.031964   \n\n             7         8         9    ...       290       291       292  \\\n0       0.310755  0.042518  0.117582  ...  0.040898  0.089389 -0.038331   \n1       0.340235 -0.226799  0.153182  ... -0.226059  0.021316  0.165585   \n2       0.411702 -0.270468  0.188854  ...  0.238225 -0.231371  0.171309   \n3       0.187045  0.016369  0.223402  ... -0.358097 -0.046825  0.253699   \n4       0.197191  0.007566 -0.078022  ... -0.282879 -0.082614 -0.037469   \n...          ...       ...       ...  ...       ...       ...       ...   \n144288  0.179262 -0.125040  0.049011  ... -0.081069 -0.059478  0.306995   \n144289  0.423479 -0.186880  0.062058  ... -0.035500  0.087183  0.009583   \n144290  0.257522 -0.072118  0.236993  ... -0.241572 -0.057554  0.245067   \n144291  0.152788 -0.034932  0.133722  ... -0.350604  0.153736 -0.099569   \n144292  0.167556  0.101673  0.102469  ... -0.029669 -0.010259 -0.175080   \n\n             293       294       295       296       297       298       299  \n0       0.134966  0.125776  0.047613  0.118618 -0.082383 -0.142240 -0.050848  \n1       0.079438  0.025206  0.240427 -0.124433 -0.023450 -0.128410 -0.236934  \n2       0.204717 -0.140009  0.122218  0.293683 -0.191857  0.037476 -0.227324  \n3       0.211709  0.026575  0.140188 -0.088641 -0.011999 -0.219470 -0.020468  \n4       0.197718  0.271753  0.094493  0.132802 -0.101094 -0.163882 -0.076224  \n...          ...       ...       ...       ...       ...       ...       ...  \n144288  0.275422 -0.285694  0.060659  0.162306 -0.075434 -0.044172  0.043803  \n144289  0.109173  0.105867  0.171229  0.076693  0.062442  0.101581 -0.254318  \n144290  0.071724 -0.168804  0.109397 -0.016880 -0.108166 -0.128291 -0.122228  \n144291  0.041787 -0.027424 -0.122549  0.268015 -0.116131 -0.194821  0.118828  \n144292  0.119183  0.015783  0.149192  0.238205  0.077856  0.176599  0.000621  \n\n[144293 rows x 300 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>290</th>\n      <th>291</th>\n      <th>292</th>\n      <th>293</th>\n      <th>294</th>\n      <th>295</th>\n      <th>296</th>\n      <th>297</th>\n      <th>298</th>\n      <th>299</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.215482</td>\n      <td>0.056077</td>\n      <td>0.215897</td>\n      <td>-0.039115</td>\n      <td>-0.250837</td>\n      <td>-0.415031</td>\n      <td>-0.101325</td>\n      <td>0.310755</td>\n      <td>0.042518</td>\n      <td>0.117582</td>\n      <td>...</td>\n      <td>0.040898</td>\n      <td>0.089389</td>\n      <td>-0.038331</td>\n      <td>0.134966</td>\n      <td>0.125776</td>\n      <td>0.047613</td>\n      <td>0.118618</td>\n      <td>-0.082383</td>\n      <td>-0.142240</td>\n      <td>-0.050848</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.279157</td>\n      <td>-0.057534</td>\n      <td>0.076047</td>\n      <td>-0.177353</td>\n      <td>0.113635</td>\n      <td>-0.216639</td>\n      <td>0.000805</td>\n      <td>0.340235</td>\n      <td>-0.226799</td>\n      <td>0.153182</td>\n      <td>...</td>\n      <td>-0.226059</td>\n      <td>0.021316</td>\n      <td>0.165585</td>\n      <td>0.079438</td>\n      <td>0.025206</td>\n      <td>0.240427</td>\n      <td>-0.124433</td>\n      <td>-0.023450</td>\n      <td>-0.128410</td>\n      <td>-0.236934</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.160039</td>\n      <td>0.252769</td>\n      <td>0.195136</td>\n      <td>0.229320</td>\n      <td>-0.405540</td>\n      <td>-0.110455</td>\n      <td>-0.073409</td>\n      <td>0.411702</td>\n      <td>-0.270468</td>\n      <td>0.188854</td>\n      <td>...</td>\n      <td>0.238225</td>\n      <td>-0.231371</td>\n      <td>0.171309</td>\n      <td>0.204717</td>\n      <td>-0.140009</td>\n      <td>0.122218</td>\n      <td>0.293683</td>\n      <td>-0.191857</td>\n      <td>0.037476</td>\n      <td>-0.227324</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.453910</td>\n      <td>-0.089990</td>\n      <td>0.237365</td>\n      <td>-0.084725</td>\n      <td>-0.169180</td>\n      <td>-0.238084</td>\n      <td>0.099591</td>\n      <td>0.187045</td>\n      <td>0.016369</td>\n      <td>0.223402</td>\n      <td>...</td>\n      <td>-0.358097</td>\n      <td>-0.046825</td>\n      <td>0.253699</td>\n      <td>0.211709</td>\n      <td>0.026575</td>\n      <td>0.140188</td>\n      <td>-0.088641</td>\n      <td>-0.011999</td>\n      <td>-0.219470</td>\n      <td>-0.020468</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.048142</td>\n      <td>0.044558</td>\n      <td>0.000380</td>\n      <td>-0.095190</td>\n      <td>0.029367</td>\n      <td>-0.226655</td>\n      <td>0.159691</td>\n      <td>0.197191</td>\n      <td>0.007566</td>\n      <td>-0.078022</td>\n      <td>...</td>\n      <td>-0.282879</td>\n      <td>-0.082614</td>\n      <td>-0.037469</td>\n      <td>0.197718</td>\n      <td>0.271753</td>\n      <td>0.094493</td>\n      <td>0.132802</td>\n      <td>-0.101094</td>\n      <td>-0.163882</td>\n      <td>-0.076224</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>144288</th>\n      <td>-0.339769</td>\n      <td>-0.107381</td>\n      <td>0.009420</td>\n      <td>0.045568</td>\n      <td>-0.118220</td>\n      <td>-0.078068</td>\n      <td>-0.028155</td>\n      <td>0.179262</td>\n      <td>-0.125040</td>\n      <td>0.049011</td>\n      <td>...</td>\n      <td>-0.081069</td>\n      <td>-0.059478</td>\n      <td>0.306995</td>\n      <td>0.275422</td>\n      <td>-0.285694</td>\n      <td>0.060659</td>\n      <td>0.162306</td>\n      <td>-0.075434</td>\n      <td>-0.044172</td>\n      <td>0.043803</td>\n    </tr>\n    <tr>\n      <th>144289</th>\n      <td>-0.293207</td>\n      <td>-0.095126</td>\n      <td>-0.027711</td>\n      <td>-0.098639</td>\n      <td>-0.409341</td>\n      <td>-0.207911</td>\n      <td>0.046775</td>\n      <td>0.423479</td>\n      <td>-0.186880</td>\n      <td>0.062058</td>\n      <td>...</td>\n      <td>-0.035500</td>\n      <td>0.087183</td>\n      <td>0.009583</td>\n      <td>0.109173</td>\n      <td>0.105867</td>\n      <td>0.171229</td>\n      <td>0.076693</td>\n      <td>0.062442</td>\n      <td>0.101581</td>\n      <td>-0.254318</td>\n    </tr>\n    <tr>\n      <th>144290</th>\n      <td>0.082674</td>\n      <td>0.141088</td>\n      <td>-0.100725</td>\n      <td>0.057958</td>\n      <td>-0.141860</td>\n      <td>-0.138624</td>\n      <td>0.151382</td>\n      <td>0.257522</td>\n      <td>-0.072118</td>\n      <td>0.236993</td>\n      <td>...</td>\n      <td>-0.241572</td>\n      <td>-0.057554</td>\n      <td>0.245067</td>\n      <td>0.071724</td>\n      <td>-0.168804</td>\n      <td>0.109397</td>\n      <td>-0.016880</td>\n      <td>-0.108166</td>\n      <td>-0.128291</td>\n      <td>-0.122228</td>\n    </tr>\n    <tr>\n      <th>144291</th>\n      <td>-0.259409</td>\n      <td>0.091483</td>\n      <td>0.181957</td>\n      <td>0.074490</td>\n      <td>-0.042760</td>\n      <td>-0.090822</td>\n      <td>0.177005</td>\n      <td>0.152788</td>\n      <td>-0.034932</td>\n      <td>0.133722</td>\n      <td>...</td>\n      <td>-0.350604</td>\n      <td>0.153736</td>\n      <td>-0.099569</td>\n      <td>0.041787</td>\n      <td>-0.027424</td>\n      <td>-0.122549</td>\n      <td>0.268015</td>\n      <td>-0.116131</td>\n      <td>-0.194821</td>\n      <td>0.118828</td>\n    </tr>\n    <tr>\n      <th>144292</th>\n      <td>0.002290</td>\n      <td>0.171757</td>\n      <td>0.084544</td>\n      <td>0.020463</td>\n      <td>-0.233254</td>\n      <td>-0.198676</td>\n      <td>0.031964</td>\n      <td>0.167556</td>\n      <td>0.101673</td>\n      <td>0.102469</td>\n      <td>...</td>\n      <td>-0.029669</td>\n      <td>-0.010259</td>\n      <td>-0.175080</td>\n      <td>0.119183</td>\n      <td>0.015783</td>\n      <td>0.149192</td>\n      <td>0.238205</td>\n      <td>0.077856</td>\n      <td>0.176599</td>\n      <td>0.000621</td>\n    </tr>\n  </tbody>\n</table>\n<p>144293 rows × 300 columns</p>\n</div>"},"metadata":{}}],"execution_count":300},{"cell_type":"code","source":"#!g1.1\n#from tqdm import tqdm\n# https://github.com/tqdm/tqdm\nfrom sklearn.ensemble import RandomForestClassifier\n#rfc = RandomForestClassifier(n_estimators=300, random_state=5)\nrfc = RandomForestClassifier()\nrfc.fit(x_train, y_train)","metadata":{"cellId":"9pronnzctbio86wy0044jb","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"CPU times: user 0 ns, sys: 0 ns, total: 0 ns\nWall time: 7.87 µs\n"},{"output_type":"display_data","data":{"text/plain":"RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n                       criterion='gini', max_depth=None, max_features='auto',\n                       max_leaf_nodes=None, max_samples=None,\n                       min_impurity_decrease=0.0, min_impurity_split=None,\n                       min_samples_leaf=1, min_samples_split=2,\n                       min_weight_fraction_leaf=0.0, n_estimators=100,\n                       n_jobs=None, oob_score=False, random_state=None,\n                       verbose=0, warm_start=False)"},"metadata":{}}],"execution_count":193},{"cell_type":"code","source":"#!g1.1\nimport pickle\n# Save the model\nmodel_src = 'content/models/random_forest_classifier.pickle'\n\npickle.dump(rfc, open(model_src, 'wb'))","metadata":{"cellId":"tmk9nb1fztkknk4r5hu8s","trusted":true},"outputs":[],"execution_count":197},{"cell_type":"code","source":"#!g1.1\nfrom sklearn.linear_model import SGDClassifier\n\n#model_sgd = SGDClassifier(class_weight={1:.99})\nmodel_sgd = SGDClassifier(\n    random_state=None,\n    class_weight=None,\n    loss='perceptron', \n    penalty='l2'\n)\nmodel_sgd.fit(x_train, y_train)","metadata":{"cellId":"3d63z8n1ystx3cr80afpjk","trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n              l1_ratio=0.15, learning_rate='optimal', loss='perceptron',\n              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n              power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n              validation_fraction=0.1, verbose=0, warm_start=False)"},"metadata":{}}],"execution_count":301},{"cell_type":"markdown","source":"# 7 Check the classifier ","metadata":{"cellId":"wtj15chdagga3abr9xh9"}},{"cell_type":"code","source":"def chk_classifier(prediction, validation):\n\n    print(\"*** Check and calculate the metrics ourselves ***\")\n\n    # model prediction result\n    a_check = prediction\n    # Validation resuls  \n    b_check = np.array(validation)\n    # проверим размерность\n    print(\"Check shapes of the prediction and Y validation:\", a_check.shape, b_check.shape)\n\n    # True Negative Predicted - false, Real - false\n    ab_diff_tn = []\n    # False Negative Predicted - false, Real - True\n    ab_diff_fn = []\n    # False positive Predicted - True, Real - False\n    ab_diff_fp = []\n    # True positive Predicted - True, Real - True\n    ab_diff_tp = []\n\n    print('')\n    print('******')\n\n    for indx in range(len(a_check)):\n        if (a_check[indx] == True):\n            if (b_check[indx] == True):\n                ab_diff_tp.append(indx)\n            else:\n                ab_diff_fp.append(indx)\n        else:\n            if (b_check[indx] == True):\n                ab_diff_fn.append(indx)\n            else:\n                ab_diff_tn.append(indx)\n\n    tn =  len(ab_diff_tn)\n    fn =  len(ab_diff_fn)\n    fp =  len(ab_diff_fp)\n    tp =  len(ab_diff_tp)\n\n    print(f\"True Negative:  {tn}  | False Positive:  {fp}\")\n    print(f\"False Negative: {fn}   | True Positive:  {tp}\")\n\n    print(f\"Precision = {tp} / ( {tp} + {fp} ) = {round(tp/(tp+fp), 2)}\")\n    print(f\"Recall = {tp} / ( {tp} + {fn} ) = {round(tp/(tp+fn), 2) }\")\n\n    print('')\n    print('******')\n    print(f\"Accurracy = {round(metrics.accuracy_score(a_check, b_check), 2) }\")\n    print(f\"F1 Score = {round(metrics.f1_score(a_check, b_check, average='weighted'), 2) }\")\n    ","metadata":{"cellId":"boj54ytktxtlydi2kda61","trusted":true},"outputs":[],"execution_count":302},{"cell_type":"code","source":"print(\"*** Check the model by the validation data ***\")\n\npredicted_sgd = model_sgd.predict(x_val)\nprint(metrics.classification_report(predicted_sgd, y_val))","metadata":{"cellId":"vx7zlwee3xie99afgkowat","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"*** Check the model by the validation data ***\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00    142478\n           1       0.93      0.96      0.94      1815\n\n    accuracy                           1.00    144293\n   macro avg       0.97      0.98      0.97    144293\nweighted avg       1.00      1.00      1.00    144293\n\n"}],"execution_count":303},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\naccuracy_score(predicted_sgd, y_val)","metadata":{"cellId":"xbx5yq2igyc3ekkxeo6zr7","trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"0.9985654189738934"},"metadata":{}}],"execution_count":304},{"cell_type":"code","source":"chk_classifier(predicted_sgd.view(), y_val)","metadata":{"cellId":"n8zvwh3p1h89p1vsvpw1w7","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"*** Check and calculate the metrics ourselves ***\nCheck shapes of the prediction and Y validation: (144293,) (144293,)\n\n******\nTrue Negative:  142350  | False Positive:  79\nFalse Negative: 128   | True Positive:  1736\nPrecision = 1736 / ( 1736 + 79 ) = 0.96\nRecall = 1736 / ( 1736 + 128 ) = 0.93\n\n******\nAccurracy = 1.0\nF1 Score = 1.0\n"}],"execution_count":305},{"cell_type":"markdown","source":"# 8 BERT-like models","metadata":{"cellId":"o9tqajy4b0mahb1j88w1ph"}},{"cell_type":"code","source":"#!g1.1\n# https://huggingface.co/DeepPavlov/rubert-base-cased\n\n# from transformers import AutoTokenizer, AutoModel\n  \n# tokenizer = AutoTokenizer.from_pretrained(\"DeepPavlov/rubert-base-cased\")\n\n# model = AutoModel.from_pretrained(\"DeepPavlov/rubert-base-cased\")\n\n# import transformers\n# from transformers import AutoTokenizer, AutoModel\n\n# # Load the BERT tokenizer.\n# print('Loading BERT tokenizer...')\n# #tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-uncased', do_lower_case=True)\n# tokenizer = AutoTokenizer.from_pretrained(\"DeepPavlov/rubert-base-cased\")","metadata":{"cellId":"q6qydggpmuqqh7cph9gd"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#!g1.1\nimport torch\n\n# If there's a GPU available...\nif torch.cuda.is_available():    \n\n    # Tell PyTorch to use the GPU.    \n    device = torch.device(\"cuda\")\n\n    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n\n    print('We will use the GPU:', torch.cuda.get_device_name(0))\n\n# If not...\nelse:\n    print('No GPU available, using the CPU instead.')\n    device = torch.device(\"cpu\")","metadata":{"cellId":"kyp1whmt3vir6nte03hvvh","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"There are 1 GPU(s) available.\nWe will use the GPU: Tesla V100-SXM2-32GB\n"}],"execution_count":306},{"cell_type":"code","source":"#!g1.1\nimport transformers\nfrom transformers import BertTokenizer\n\n# Load the BERT tokenizer.\nprint('Loading BERT tokenizer...')\n#tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-uncased', do_lower_case=True)\ntokenizer = AutoTokenizer.from_pretrained(\"DeepPavlov/rubert-base-cased\")","metadata":{"cellId":"yxvoq6ji43qx9qsneg60ci","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"Loading BERT tokenizer...\n"}],"execution_count":336},{"cell_type":"code","source":"#!g1.1\n\nsentences = df_train.cleaned_text.values\nlabels = df_train.label.values\n\n# Print the original sentence.\nprint(' Original: ', sentences[0])\n\n# Print the sentence split into tokens.\nprint('Tokenized: ', tokenizer.tokenize(sentences[0]))\n\n# Print the sentence mapped to token ids.\nprint('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))","metadata":{"cellId":"hkm8dappjqo6ijzdlnue4","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":" Original:  наборы фигурок миньоны\nTokenized:  ['наборы', 'фигурок', 'мин', '##ьон', '##ы']\nToken IDs:  [74470, 105592, 6186, 45898, 880]\n"}],"execution_count":337},{"cell_type":"code","source":"#!g1.1\nsentences = \"Our friends won't buy this analysis, let alone the next one we propose.\"\n\n# Print the original sentence.\nprint(' Original: ', sentences)\n\n# Print the sentence split into tokens.\nprint('Tokenized: ', tokenizer.tokenize(sentences))\n\n# Print the sentence mapped to token ids.\nprint('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences)))","metadata":{"cellId":"5x8xtfzoavani18vup4uze","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":" Original:  Our friends won't buy this analysis, let alone the next one we propose.\nTokenized:  ['our', 'fri', '##ends', 'wo', '##n', \"'\", 't', 'bu', '##y', 'this', 'anal', '##ysis', ',', 'let', 'al', '##one', 'the', 'ne', '##xt', 'one', 'we', 'prop', '##ose', '.']\nToken IDs:  [17958, 35862, 50842, 13308, 259, 118, 270, 12011, 281, 11043, 107127, 66861, 128, 14107, 10676, 13438, 10617, 11066, 29395, 10976, 12463, 30557, 15081, 132]\n"}],"execution_count":338},{"cell_type":"code","source":"# #!g1.1\n# from transformers import AutoTokenizer, AutoModelForSequenceClassification\n# # from transformers import AutoModelForSequenceClassification\n# from transformers import BertTokenizerFast\n\n# #tokenizer = AutoTokenizer.from_pretrained(\"IlyaGusev/xlm_roberta_large_headline_cause_full\")\n# tokenizer = AutoTokenizer.from_pretrained(\"IlyaGusev/xlm_roberta_large_headline_cause_full\")\n# # tokenizer = BertTokenizerFast.from_pretrained('blanchefort/rubert-base-cased-sentiment')\n# #tokenizer = BertTokenizerFast.from_pretrained('blanchefort/rubert-base-cased-sentiment')","metadata":{"cellId":"22voewxhmhtj24blqiueyo8","trusted":true},"outputs":[],"execution_count":339},{"cell_type":"code","source":"#!g1.1\n","metadata":{"cellId":"xf7ez53cqhp3ciu9g1nj"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#!g1.1\n","metadata":{"cellId":"fmieg5nzp8wcya22vh0a3b"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#!g1.1\n","metadata":{"cellId":"10ya86068r5d77bcmvkgff"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#!g1.1\n","metadata":{"cellId":"fr53prdaczim20vvz9rog"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#!g1.1\n","metadata":{"cellId":"mh3cjlodxemg8g61rf5v"},"outputs":[],"execution_count":null}]}